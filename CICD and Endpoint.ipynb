{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32c528d0-3273-481a-9552-3338d20d68bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shap\n",
      "  Using cached shap-0.46.0-cp311-cp311-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from shap) (1.15.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (from shap) (1.5.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from shap) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /opt/conda/lib/python3.11/site-packages (from shap) (4.67.1)\n",
      "Requirement already satisfied: packaging>20.9 in /opt/conda/lib/python3.11/site-packages (from shap) (24.2)\n",
      "Collecting slicer==0.0.8 (from shap)\n",
      "  Using cached slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.11/site-packages (from shap) (0.61.0)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.11/site-packages (from shap) (2.2.1)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba->shap) (0.44.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->shap) (2025.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
      "Using cached shap-0.46.0-cp311-cp311-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (540 kB)\n",
      "Using cached slicer-0.0.8-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: slicer, shap\n",
      "Successfully installed shap-0.46.0 slicer-0.0.8\n"
     ]
    }
   ],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48042a79-3e63-4629-80f9-50c5842aaf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "Loaded 10000 rows and 22 features from X_prod_final.\n",
      "Loaded 10000 target values from y_prod.\n",
      "Loaded 12500 rows and 22 features from X_train_final.\n",
      "Loaded 12500 target values from y_train.\n"
     ]
    }
   ],
   "source": [
    "import model_methods\n",
    "import json\n",
    "import joblib\n",
    "import os\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.predictor import Predictor\n",
    "import boto3\n",
    "import tarfile\n",
    "import io\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "s3_client = boto3.client(\"s3\")\n",
    "model_package_group_name = \"xgboost-hospital-readmissions-1740627359\"\n",
    "bucket_name = \"group3-project-bucket\"\n",
    "\n",
    "def load_from_prod(bucket, key):\n",
    "    response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    return pd.read_csv(io.BytesIO(response['Body'].read()))\n",
    "\n",
    "X_prod_file = \"production_data/X_prod_final.csv\"\n",
    "y_prod_file = \"production_data/y_prod.csv\"\n",
    "X_train_file = \"production_data/X_train_final.csv\"\n",
    "y_train_file = \"production_data/y_train.csv\"\n",
    "\n",
    "\n",
    "X_prod_final = load_from_prod(bucket_name, X_prod_file)\n",
    "y_prod = load_from_prod(bucket_name, y_prod_file)\n",
    "\n",
    "X_train_final = load_from_prod(bucket_name, X_train_file)\n",
    "y_train = load_from_prod(bucket_name, y_train_file)\n",
    "\n",
    "print(f\"Loaded {X_prod_final.shape[0]} rows and {X_prod_final.shape[1]} features from X_prod_final.\")\n",
    "print(f\"Loaded {y_prod.shape[0]} target values from y_prod.\")\n",
    "\n",
    "print(f\"Loaded {X_train_final.shape[0]} rows and {X_train_final.shape[1]} features from X_train_final.\")\n",
    "print(f\"Loaded {y_train.shape[0]} target values from y_train.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4782c0cd-50d9-4333-b823-be05d3285ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ARN: arn:aws:sagemaker:us-east-1:321261761338:model-package/xgboost-hospital-readmissions-1740627359/1\n",
      "Approval Status: PendingManualApproval\n",
      "Creation Time: 2025-02-27 03:36:01.326000+00:00\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# List all models (approved or not)\n",
    "response = sm_client.list_model_packages(\n",
    "    ModelPackageGroupName=model_package_group_name,\n",
    "    SortBy=\"CreationTime\",\n",
    "    SortOrder=\"Descending\",\n",
    "    MaxResults=5,  # Show up to 5 latest models\n",
    ")\n",
    "\n",
    "if not response[\"ModelPackageSummaryList\"]:\n",
    "    raise ValueError(f\"No models exist in Model Package Group: {model_package_group_name}\")\n",
    "\n",
    "# Print available models and their approval status\n",
    "for model in response[\"ModelPackageSummaryList\"]:\n",
    "    print(f\"Model ARN: {model['ModelPackageArn']}\")\n",
    "    print(f\"Approval Status: {model['ModelApprovalStatus']}\")\n",
    "    print(f\"Creation Time: {model['CreationTime']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f17253f1-6dd3-481e-8eb5-7bc706819287",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_model_arn = \"arn:aws:sagemaker:us-east-1:321261761338:model-package/xgboost-hospital-readmissions-1740627359/1\"\n",
    "response = sm_client.update_model_package(\n",
    "    ModelPackageArn=latest_model_arn,\n",
    "    ModelApprovalStatus=\"Approved\",\n",
    "    ApprovalDescription=\"Approved for deployment\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a264d95-7bca-4ffa-9580-6e0b72a4c7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using Model Package: arn:aws:sagemaker:us-east-1:321261761338:model-package/xgboost-hospital-readmissions-1740627359/1\n",
      "✅ Extracted Model Artifact from S3: s3://group3-project-bucket/hospital-readmissions-xgboost/model-1740627360.tar.gz\n",
      "✅ Model Artifact: s3://group3-project-bucket/hospital-readmissions-xgboost/model-1740627360.tar.gz\n",
      "✅ Model Container Image: 683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.5-1\n"
     ]
    }
   ],
   "source": [
    "# Get the latest approved model package\n",
    "response = sm_client.list_model_packages(\n",
    "    ModelPackageGroupName=model_package_group_name,\n",
    "    SortBy=\"CreationTime\",\n",
    "    SortOrder=\"Descending\",\n",
    "    ModelApprovalStatus=\"Approved\",  # Only get models that are approved for deployment\n",
    "    MaxResults=1,\n",
    ")\n",
    "\n",
    "if not response[\"ModelPackageSummaryList\"]:\n",
    "    raise ValueError(f\"No approved models found in Model Package Group: {model_package_group_name}\")\n",
    "\n",
    "latest_model_package_arn = response[\"ModelPackageSummaryList\"][0][\"ModelPackageArn\"]\n",
    "print(f\"✅ Using Model Package: {latest_model_package_arn}\")\n",
    "\n",
    "# Get model details to extract S3 path of the trained model\n",
    "model_details = sm_client.describe_model_package(ModelPackageName=latest_model_package_arn)\n",
    "model_s3_uri = model_details[\"InferenceSpecification\"][\"Containers\"][0][\"ModelDataUrl\"]\n",
    "model_image_uri = model_details[\"InferenceSpecification\"][\"Containers\"][0][\"Image\"]\n",
    "\n",
    "print(f\"✅ Extracted Model Artifact from S3: {model_s3_uri}\")\n",
    "\n",
    "print(f\"✅ Model Artifact: {model_s3_uri}\")\n",
    "print(f\"✅ Model Container Image: {model_image_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86b5fb2-715b-4d8c-8006-9ca596f53cde",
   "metadata": {},
   "source": [
    "## Mock Endpoint\n",
    "CreateModel permissions are not available for any member of our group, so we have created a Mock endpoint that utilizes our latest model to simulate endpoint states as if our model was working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd1aecbb-c084-470b-934e-c7b7dc6fee41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model downloaded: /tmp/tmp5y207p23/model.tar.gz\n",
      "✅ Model extracted at: /tmp/tmp5y207p23/extracted_model\n",
      "🔍 Extracted Files: ['model.joblib']\n",
      "✅ Model loaded successfully from: /tmp/tmp5y207p23/extracted_model/model.joblib\n",
      "<xgboost.core.Booster object at 0x7ffa14176690>\n"
     ]
    }
   ],
   "source": [
    "## Download Model\n",
    "import tempfile\n",
    "\n",
    "def download_model(model_uri):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    bucket_name = model_uri.split(\"/\")[2]\n",
    "    model_key = \"/\".join(model_uri.split(\"/\")[3:])\n",
    "    \n",
    "    # Save to a temporary directory\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    local_model_path = os.path.join(temp_dir, \"model.tar.gz\")\n",
    "    \n",
    "    # Download the model file\n",
    "    s3.download_file(bucket_name, model_key, local_model_path)\n",
    "    print(f\"✅ Model downloaded: {local_model_path}\")\n",
    "    \n",
    "    # Extract the model\n",
    "    extracted_model_path = os.path.join(temp_dir, \"extracted_model\")\n",
    "    with tarfile.open(local_model_path, \"r:gz\") as tar:\n",
    "        tar.extractall(extracted_model_path)\n",
    "    \n",
    "    print(f\"✅ Model extracted at: {extracted_model_path}\")\n",
    "    \n",
    "    # Find the `model.joblib` file\n",
    "    extracted_files = os.listdir(extracted_model_path)\n",
    "    print(f\"🔍 Extracted Files: {extracted_files}\")\n",
    "    \n",
    "    model_file_path = os.path.join(extracted_model_path, \"model.joblib\")\n",
    "    \n",
    "    if not os.path.exists(model_file_path):\n",
    "        raise FileNotFoundError(\"🚨 `model.joblib` file not found after extraction!\")\n",
    "    \n",
    "    # Load the model using joblib\n",
    "    model = joblib.load(model_file_path)\n",
    "    print(f\"✅ Model loaded successfully from: {model_file_path}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "class MockEndpoint():\n",
    "    def __init__(self, model_s3_uri):\n",
    "        self.model_s3_uri = model_s3_uri\n",
    "        self.model = download_model(model_s3_uri)\n",
    "    \n",
    "    def predict(self, data):\n",
    "        features = self.model.feature_names\n",
    "        dmatrix = xgb.DMatrix(data[features])\n",
    "        predictions = self.model.predict(dmatrix)\n",
    "        \n",
    "        return json.dumps({\"predictions\": predictions.tolist()})\n",
    "\n",
    "mock_endpoint = MockEndpoint(model_s3_uri)\n",
    "\n",
    "print(mock_endpoint.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0306685c-b28b-404d-94b6-0975ed152d55",
   "metadata": {},
   "source": [
    "## Mock Bias Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3447faa8-1f09-4799-b8c3-6635eb752b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'time_in_hospital', 'n_lab_procedures', 'n_procedures',\n",
      "       'n_medications', 'n_outpatient', 'n_inpatient', 'n_emergency',\n",
      "       'medical_specialty', 'diag_1', 'diag_2', 'diag_3', 'glucose_test',\n",
      "       'a1ctest', 'change', 'diabetes_med', 'n_inpatient_x_n_lab_procedures',\n",
      "       'n_inpatient_x_n_medications', 'n_inpatient_x_time_in_hospital',\n",
      "       'n_lab_procedures_x_n_medications',\n",
      "       'n_lab_procedures_x_time_in_hospital',\n",
      "       'n_medications_x_time_in_hospital'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_prod_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "350c64cd-60d9-410f-8601-b3561419a75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Quantile Edges: [ 26.  54. 108.]\n",
      "Training Data Quartile Distribution:\n",
      " facet_category\n",
      "Low            3264\n",
      "High           3112\n",
      "Medium-High    3090\n",
      "Medium-Low     3034\n",
      "Name: count, dtype: int64\n",
      "Production Data Quartile Distribution:\n",
      " facet_category\n",
      "Low            2718\n",
      "Medium-High    2515\n",
      "High           2415\n",
      "Medium-Low     2352\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Compute quartile bin edges using training data\n",
    "quantile_bins = X_train_final[\"n_medications_x_time_in_hospital\"].quantile([0.25, 0.5, 0.75]).values\n",
    "print(f\"Training Set Quantile Edges: {quantile_bins}\")\n",
    "\n",
    "# Create categorical labels\n",
    "quartile_labels = [\"Low\", \"Medium-Low\", \"Medium-High\", \"High\"]\n",
    "\n",
    "# Apply training quartiles to both training & production datasets\n",
    "X_train_final[\"facet_category\"] = pd.cut(\n",
    "    X_train_final[\"n_medications_x_time_in_hospital\"], \n",
    "    bins=[-np.inf] + quantile_bins.tolist() + [np.inf], \n",
    "    labels=quartile_labels\n",
    ")\n",
    "\n",
    "X_prod_final[\"facet_category\"] = pd.cut(\n",
    "    X_prod_final[\"n_medications_x_time_in_hospital\"], \n",
    "    bins=[-np.inf] + quantile_bins.tolist() + [np.inf], \n",
    "    labels=quartile_labels\n",
    ")\n",
    "\n",
    "# Print category distributions\n",
    "print(\"Training Data Quartile Distribution:\\n\", X_train_final[\"facet_category\"].value_counts())\n",
    "print(\"Production Data Quartile Distribution:\\n\", X_prod_final[\"facet_category\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10db9249-c2de-4787-9091-980d43baf687",
   "metadata": {},
   "source": [
    "## Bias Report\n",
    "\n",
    "### Pre-training Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b233a4c4-6b8e-49a1-b733-d2077f67f7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2843/2465601509.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  label_proportions = y_train.groupby(X_train_final[\"facet_category\"]).mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facet_category</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Low</th>\n",
       "      <td>0.413297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medium-Low</th>\n",
       "      <td>0.462755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medium-High</th>\n",
       "      <td>0.499029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High</th>\n",
       "      <td>0.499357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                readmitted\n",
       "facet_category            \n",
       "Low               0.413297\n",
       "Medium-Low        0.462755\n",
       "Medium-High       0.499029\n",
       "High              0.499357"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Class Imbalance:\n",
      " readmitted\n",
      "0             0.53208\n",
      "1             0.46792\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "label_proportions = y_train.groupby(X_train_final[\"facet_category\"]).mean()\n",
    "display(label_proportions)\n",
    "\n",
    "label_imbalance = y_train.value_counts(normalize=True)\n",
    "print(\"Label Class Imbalance:\\n\", label_imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "117e0840-624f-4a48-9a62-6970ea7b2a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in Proportions of Labels (DPL): 0.0861\n"
     ]
    }
   ],
   "source": [
    "dpl = label_proportions.loc[\"High\", \"readmitted\"] - label_proportions.loc[\"Low\", \"readmitted\"]\n",
    "\n",
    "print(f\"Difference in Proportions of Labels (DPL): {dpl:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9fd005-e56e-4b40-a9ff-637e979b4291",
   "metadata": {},
   "source": [
    "### Post-Training Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de200cd0-109d-4f67-a4b5-f193f0028a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Parity Difference (SPD): 0.1985\n",
      "Disparate Impact (DI): 1.6734\n",
      "Accuracy Difference (AD): -0.0402\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Create empty dictionary to store predictions\n",
    "category_preds = {}\n",
    "\n",
    "# Get predictions per quartile\n",
    "for category in quartile_labels:\n",
    "    subset = X_prod_final[X_prod_final[\"facet_category\"] == category]\n",
    "    preds = json.loads(mock_endpoint.predict(subset))[\"predictions\"]\n",
    "    category_preds[category] = preds\n",
    "\n",
    "# Compute acceptance rates per quartile\n",
    "p_high_pred = (np.array(category_preds[\"High\"]) > 0.5).mean()\n",
    "p_low_pred = (np.array(category_preds[\"Low\"]) > 0.5).mean()\n",
    "\n",
    "spd = p_high_pred - p_low_pred\n",
    "print(f\"Statistical Parity Difference (SPD): {spd:.4f}\")\n",
    "\n",
    "di = p_high_pred / (p_low_pred + 1e-8)\n",
    "print(f\"Disparate Impact (DI): {di:.4f}\")\n",
    "\n",
    "y_high = y_prod.loc[X_prod_final[\"facet_category\"] == \"High\"].values\n",
    "y_low = y_prod.loc[X_prod_final[\"facet_category\"] == \"Low\"].values\n",
    "\n",
    "# Ensure category_preds[\"High\"] is a NumPy array\n",
    "accuracy_high = (np.round(np.array(category_preds[\"High\"])) == y_high).mean()\n",
    "accuracy_low = (np.round(np.array(category_preds[\"Low\"])) == y_low).mean()\n",
    "\n",
    "ad = accuracy_high - accuracy_low\n",
    "print(f\"Accuracy Difference (AD): {ad:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "108a2c59-6d3e-4ab7-9e4a-2e0b909f00d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias report saved as JSON to S3: s3://group3-project-bucket/bias_reports/bias_report_xgboost-hospital-readmissions-1740627359.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "# Convert Bias Metrics to JSON\n",
    "bias_report = {\n",
    "    \"Pre-Training Bias\": {\n",
    "        \"Label Imbalance\": {\n",
    "            \"Class 0\": round(label_imbalance.get(0, 0), 4),\n",
    "            \"Class 1\": round(label_imbalance.get(1, 0), 4)\n",
    "        },\n",
    "        \"Difference in Proportions of Labels (DPL)\": round(dpl, 4)\n",
    "    },\n",
    "    \"Post-Training Bias\": {\n",
    "        \"Statistical Parity Difference (SPD)\": round(spd, 4),\n",
    "        \"Disparate Impact (DI)\": round(di, 4),\n",
    "        \"Accuracy Difference (AD)\": round(ad, 4)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert to JSON string\n",
    "bias_report_json = json.dumps(bias_report, indent=4)\n",
    "\n",
    "# S3 Configuration\n",
    "s3_filename = f\"bias_reports/bias_report_{model_package_group_name}.json\"\n",
    "s3_uri = f\"s3://{bucket_name}/{s3_filename}\"\n",
    "\n",
    "# Save to S3\n",
    "s3_client.put_object(\n",
    "    Bucket=bucket_name,\n",
    "    Key=s3_filename,\n",
    "    Body=bias_report_json\n",
    ")\n",
    "\n",
    "print(f\"Bias report saved as JSON to S3: {s3_uri}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5112e78f-3ef3-4469-8a71-4efcdd424391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Pre-Training Bias\": {\n",
      "        \"Label Imbalance\": {\n",
      "            \"Class 0\": 0.5321,\n",
      "            \"Class 1\": 0.4679\n",
      "        },\n",
      "        \"Difference in Proportions of Labels (DPL)\": 0.0861\n",
      "    },\n",
      "    \"Post-Training Bias\": {\n",
      "        \"Statistical Parity Difference (SPD)\": 0.1985,\n",
      "        \"Disparate Impact (DI)\": 1.6734,\n",
      "        \"Accuracy Difference (AD)\": -0.0402\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(bias_report_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b20985-30d6-4cfe-b8f4-89881182f5fc",
   "metadata": {},
   "source": [
    "# Bias Report Interpretation. Facet: n_medications_x_time_in_hospital\n",
    "\n",
    "This bias report provides insights into **pre-training bias (data distribution) and post-training bias (model predictions).** Let's break it down.\n",
    "\n",
    "---\n",
    "\n",
    "## **Pre-Training Bias (Before Model Training)**\n",
    "\n",
    "### **Label Imbalance**\n",
    "| Class | Proportion |\n",
    "|--------|-----------|\n",
    "| **Class 0** (Not Readmitted) | **53.21%** |\n",
    "| **Class 1** (Readmitted) | **46.79%** |\n",
    "\n",
    "**Interpretation:**  \n",
    "- The dataset is **fairly balanced**, but **slightly favors Class 0 (non-readmitted patients).**\n",
    "- **No extreme label imbalance** (e.g., 90%–10%), so training should not be overly biased toward predicting one outcome.\n",
    "\n",
    "---\n",
    "\n",
    "### **Difference in Proportions of Labels (DPL)**\n",
    "- **DPL = 0.0861** → The **High** quartile has a **higher proportion of positive labels (readmitted patients)** than the **Low** quartile.\n",
    "\n",
    "**Interpretation:**  \n",
    "- Patients in the **High quartile of `n_medications_x_time_in_hospital`** are **more likely to be labeled as readmitted** compared to the **Low quartile.**  \n",
    "- This suggests that **hospital stay duration and number of medications are correlated with readmission risk**.\n",
    "- If this correlation is **unwanted**, we may need to **adjust for this bias** in feature engineering.\n",
    "\n",
    "---\n",
    "\n",
    "## **Post-Training Bias (After Model Predictions)**\n",
    "\n",
    "### **Statistical Parity Difference (SPD)**\n",
    "- **SPD = 0.1985** → The model predicts **\"Readmitted\" (Positive Class) more often** for **patients in the High quartile** compared to those in the Low quartile.\n",
    "\n",
    "**Interpretation:**  \n",
    "- The model assigns **different readmission probabilities based on `n_medications_x_time_in_hospital` quartiles.**  \n",
    "- This could indicate **a learned bias** in favor of certain patient groups.\n",
    "\n",
    "---\n",
    "\n",
    "### **Disparate Impact (DI)**\n",
    "- **DI = 1.6734** → The **High quartile group** is **1.67 times more likely** to be predicted as \"Readmitted\" compared to the Low quartile.\n",
    "\n",
    "**Interpretation:**  \n",
    "- The model disproportionately predicts **readmissions for patients with longer hospital stays and more medications.**\n",
    "- **If DI > 1.25**, this could indicate **potential fairness concerns** (depending on legal and ethical guidelines).\n",
    "- A **DI between 0.8 and 1.25** is usually considered **fair** (depending on context).\n",
    "\n",
    "---\n",
    "\n",
    "### **Accuracy Difference (AD)**\n",
    "- **AD = -0.0402** → The model is **4% more accurate** for patients in the Low quartile than the High quartile.\n",
    "\n",
    "**Interpretation:**  \n",
    "- **Accuracy is slightly worse for patients with longer hospital stays & more medications.**\n",
    "- This suggests that the model might struggle with **complex cases requiring many medications.**\n",
    "- **Potential solution**: Improve feature representation or collect more data for High quartile patients.\n",
    "\n",
    "---\n",
    "\n",
    "## **Final Bias Report Summary**\n",
    "\n",
    "| Metric | Value | Interpretation |\n",
    "|---------|------|---------------|\n",
    "| **Class 0 Imbalance** | 53.21% | Slightly more non-readmitted patients. |\n",
    "| **Class 1 Imbalance** | 46.79% | Nearly balanced, but slight bias toward non-readmission. |\n",
    "| **DPL** | 0.0861 | Higher readmission rates in the High quartile group. |\n",
    "| **SPD** | 0.1985 | Model predicts \"Readmitted\" more often for High quartile patients. |\n",
    "| **DI** | 1.6734 | High quartile patients are **1.67x more likely** to be predicted as \"Readmitted.\" |\n",
    "| **AD** | -0.0402 | **4% lower accuracy** for High quartile patients. |\n",
    "\n",
    "---\n",
    "\n",
    "## **Recommendations**\n",
    "**Monitor fairness thresholds** (DI should ideally be between **0.8 and 1.25**).  \n",
    "**Investigate why the model predicts higher readmission for the High quartile group.**  \n",
    "**Check feature engineering** to ensure `n_medications_x_time_in_hospital` isn’t over-weighted.  \n",
    "**If necessary, balance training data** (e.g., re-weight samples or augment underrepresented groups).  \n",
    "\n",
    "**This is a well-balanced model, but there are signs of potential bias in predictions based on hospitalization length & medications.** 🚀\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
